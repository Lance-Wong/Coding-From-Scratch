{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "%pylab inline\n",
    "df=pd.read_csv('2013_movies.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year']= [x.year for x in pd.to_datetime(df.ReleaseDate)]\n",
    "df['month']= [x.month for x in pd.to_datetime(df.ReleaseDate)]\n",
    "df=df.drop(columns=['Title','Director','ReleaseDate','year'])\n",
    "df=df.dropna()\n",
    "df=pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Budget</th>\n",
       "      <th>DomesticTotalGross</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>month</th>\n",
       "      <th>Rating_PG</th>\n",
       "      <th>Rating_PG-13</th>\n",
       "      <th>Rating_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130000000.0</td>\n",
       "      <td>424668047</td>\n",
       "      <td>146</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>409013994</td>\n",
       "      <td>129</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150000000.0</td>\n",
       "      <td>400738009</td>\n",
       "      <td>108</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76000000.0</td>\n",
       "      <td>368061265</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>225000000.0</td>\n",
       "      <td>291045518</td>\n",
       "      <td>143</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Budget  DomesticTotalGross  Runtime  month  Rating_PG  Rating_PG-13  \\\n",
       "0  130000000.0           424668047      146     11          0             1   \n",
       "1  200000000.0           409013994      129      5          0             1   \n",
       "2  150000000.0           400738009      108     11          1             0   \n",
       "3   76000000.0           368061265       98      7          1             0   \n",
       "4  225000000.0           291045518      143      6          0             1   \n",
       "\n",
       "   Rating_R  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, I want to predict Domestic Total Gross using Budget, Runtime, month, and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.DomesticTotalGross\n",
    "x=df.drop(columns=['DomesticTotalGross'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Budget</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>month</th>\n",
       "      <th>Rating_PG</th>\n",
       "      <th>Rating_PG-13</th>\n",
       "      <th>Rating_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130000000.0</td>\n",
       "      <td>146</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>129</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150000000.0</td>\n",
       "      <td>108</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76000000.0</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>225000000.0</td>\n",
       "      <td>143</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Budget  Runtime  month  Rating_PG  Rating_PG-13  Rating_R\n",
       "0  130000000.0      146     11          0             1         0\n",
       "1  200000000.0      129      5          0             1         0\n",
       "2  150000000.0      108     11          1             0         0\n",
       "3   76000000.0       98      7          1             0         0\n",
       "4  225000000.0      143      6          0             1         0"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split up our dataset into a test and train set. Also, we want to normalize all the variables for faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xtrain,xtest,ytrain, ytest= train_test_split(x,y,test_size=.25,random_state=42)\n",
    "\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0, 1))\n",
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.transform(xtest)\n",
    "xtrain=np.concatenate((xtrain,np.ones([len(xtrain),1])),axis=1)\n",
    "xtest=np.concatenate((xtest,np.ones([len(xtest),1])),axis=1)               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Linear Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR():\n",
    "    def __init__(self,verbose=False,):\n",
    "        self.verbose=verbose\n",
    "        return\n",
    "    def fit(self,predictors,response,learning_rate):\n",
    "        ''' lets initialize the gradients and weights. I will iterate through them until we find convergence\n",
    "        '''\n",
    "        gradient=np.ones(len(predictors.T))\n",
    "        weights=np.ones(len(predictors.T))\n",
    "        count=0\n",
    "        '''Since the linear regression loss function is convex by way of sum(actual-predicted)^2/n, we can minimize the\\\n",
    "        loss function by bringing our gradients as close to 0 as possible'''\n",
    "        while np.mean(abs(gradient))>=.001:\n",
    "            predictions=np.dot(predictors,weights) #equivalent to x1b1 + x2b2+ xkbk across all observations            \n",
    "            MSE = sum((response-predictions) ** 2)/(2*len(predictors))\n",
    "            \n",
    "            '''Gradient descent is calculated as follows:\n",
    "                1. from the MSE equation I take partial derivitives with respect to each feature. Combined with the\n",
    "                    chain rule we get: deriv(x1)= sum(-x1(errors), where errors is y-predicted\n",
    "                2. divide gradients by number of samples in the set\n",
    "                3. Multiply result by learning rate\n",
    "                4. Subtract result from weights '''\n",
    "            \n",
    "            errors=response-predictions   \n",
    "            gradient=np.dot(-predictors.T,errors)\n",
    "            gradient/=len(predictors)\n",
    "            reduction=gradient * learning_rate\n",
    "            weights -= reduction\n",
    "            count+=1\n",
    "            \n",
    "            if self.verbose==True and count%20==0:\n",
    "                print(f'MSE: {round(MSE,0)} | iteration: {count} | avg_gradient {round(np.mean(gradient),3)}')\n",
    "        self.weights=weights\n",
    "        self.count=count\n",
    "        \n",
    "        return f\"Fit complete: {count} iterations\"\n",
    "    def predict(self,test):\n",
    "        return np.dot(test,self.weights)\n",
    "    def score(self,predictors,response):\n",
    "        SST= sum((response-np.mean(response))**2)\n",
    "        predictions=np.dot(predictors,self.weights)\n",
    "        SSE= sum( (response-predictions)**2)\n",
    "        self.R2= 1-SSE/SST\n",
    "        return self.R2\n",
    "    def coef(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 6662817695107725.0 | iteration: 20 | avg_gradient 16164826.116\n",
      "MSE: 5478201701665878.0 | iteration: 40 | avg_gradient 5217600.259\n",
      "MSE: 5348620246736620.0 | iteration: 60 | avg_gradient 1685523.252\n",
      "MSE: 5332785607357017.0 | iteration: 80 | avg_gradient 546066.503\n",
      "MSE: 5330165748636634.0 | iteration: 100 | avg_gradient 178156.062\n",
      "MSE: 5329445327750424.0 | iteration: 120 | avg_gradient 59046.238\n",
      "MSE: 5329154192098413.0 | iteration: 140 | avg_gradient 20229.135\n",
      "MSE: 5329017797327546.0 | iteration: 160 | avg_gradient 7388.057\n",
      "MSE: 5328951240364446.0 | iteration: 180 | avg_gradient 3002.99\n",
      "MSE: 5328918424414219.0 | iteration: 200 | avg_gradient 1410.043\n",
      "MSE: 5328902201349122.0 | iteration: 220 | avg_gradient 767.518\n",
      "MSE: 5328894175518715.0 | iteration: 240 | avg_gradient 468.433\n",
      "MSE: 5328890204213202.0 | iteration: 260 | avg_gradient 306.83\n",
      "MSE: 5328888239036337.0 | iteration: 280 | avg_gradient 208.67\n",
      "MSE: 5328887266563490.0 | iteration: 300 | avg_gradient 144.537\n",
      "MSE: 5328886785330238.0 | iteration: 320 | avg_gradient 100.973\n",
      "MSE: 5328886547189064.0 | iteration: 340 | avg_gradient 70.814\n",
      "MSE: 5328886429343406.0 | iteration: 360 | avg_gradient 49.748\n",
      "MSE: 5328886371026731.0 | iteration: 380 | avg_gradient 34.976\n",
      "MSE: 5328886342168353.0 | iteration: 400 | avg_gradient 24.599\n",
      "MSE: 5328886327887599.0 | iteration: 420 | avg_gradient 17.303\n",
      "MSE: 5328886320820676.0 | iteration: 440 | avg_gradient 12.171\n",
      "MSE: 5328886317323564.0 | iteration: 460 | avg_gradient 8.562\n",
      "MSE: 5328886315592996.0 | iteration: 480 | avg_gradient 6.023\n",
      "MSE: 5328886314736615.0 | iteration: 500 | avg_gradient 4.237\n",
      "MSE: 5328886314312826.0 | iteration: 520 | avg_gradient 2.981\n",
      "MSE: 5328886314103114.0 | iteration: 540 | avg_gradient 2.097\n",
      "MSE: 5328886313999334.0 | iteration: 560 | avg_gradient 1.475\n",
      "MSE: 5328886313947981.0 | iteration: 580 | avg_gradient 1.038\n",
      "MSE: 5328886313922567.0 | iteration: 600 | avg_gradient 0.73\n",
      "MSE: 5328886313909990.0 | iteration: 620 | avg_gradient 0.513\n",
      "MSE: 5328886313903767.0 | iteration: 640 | avg_gradient 0.361\n",
      "MSE: 5328886313900688.0 | iteration: 660 | avg_gradient 0.254\n",
      "MSE: 5328886313899163.0 | iteration: 680 | avg_gradient 0.179\n",
      "MSE: 5328886313898409.0 | iteration: 700 | avg_gradient 0.126\n",
      "MSE: 5328886313898036.0 | iteration: 720 | avg_gradient 0.088\n",
      "MSE: 5328886313897852.0 | iteration: 740 | avg_gradient 0.062\n",
      "MSE: 5328886313897760.0 | iteration: 760 | avg_gradient 0.044\n",
      "MSE: 5328886313897715.0 | iteration: 780 | avg_gradient 0.031\n",
      "MSE: 5328886313897692.0 | iteration: 800 | avg_gradient 0.022\n",
      "MSE: 5328886313897681.0 | iteration: 820 | avg_gradient 0.015\n",
      "MSE: 5328886313897676.0 | iteration: 840 | avg_gradient 0.011\n",
      "MSE: 5328886313897673.0 | iteration: 860 | avg_gradient 0.008\n",
      "MSE: 5328886313897672.0 | iteration: 880 | avg_gradient 0.005\n",
      "MSE: 5328886313897672.0 | iteration: 900 | avg_gradient 0.004\n",
      "MSE: 5328886313897672.0 | iteration: 920 | avg_gradient 0.003\n",
      "MSE: 5328886313897672.0 | iteration: 940 | avg_gradient 0.002\n",
      "MSE: 5328886313897670.0 | iteration: 960 | avg_gradient 0.001\n",
      "MSE: 5328886313897671.0 | iteration: 980 | avg_gradient 0.001\n",
      "MSE: 5328886313897670.0 | iteration: 1000 | avg_gradient 0.001\n",
      "MSE: 5328886313897671.0 | iteration: 1020 | avg_gradient 0.0\n",
      "MSE: 5328886313897671.0 | iteration: 1040 | avg_gradient 0.0\n",
      "MSE: 5328886313897670.0 | iteration: 1060 | avg_gradient 0.0\n",
      "MSE: 5328886313897671.0 | iteration: 1080 | avg_gradient 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fit complete: 1088 iterations'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LR(verbose=True)\n",
    "lr.fit(xtrain,ytrain,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 1.54955606e+08  1.99773865e+07 -3.34279751e+06  3.06537983e+07\n",
      " -3.60884752e+06  7.57615502e+06  3.46211038e+07]\n",
      "R2 Value: 0.27163893217302315\n"
     ]
    }
   ],
   "source": [
    "print(f'Coefficients: {lr.coef()}')\n",
    "print(f'R2 Value: {lr.score(xtrain,ytrain)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how this compares with Sci-kit Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "z=LinearRegression(fit_intercept=False)\n",
    "z.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 1.54955606e+08  1.99773863e+07 -3.34279748e+06  3.06537978e+07\n",
      " -3.60884801e+06  7.57615455e+06  3.46211043e+07]\n",
      "R2 Value: 0.27163893217302315\n"
     ]
    }
   ],
   "source": [
    "print(f'Coefficients: {z.coef_}')\n",
    "print(f'R2 Value: {z.score(xtrain,ytrain)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
